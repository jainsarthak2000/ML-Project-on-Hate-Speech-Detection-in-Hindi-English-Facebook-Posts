{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jainsarthak2000/ML-Project-on-Hate-Speech-Detection-in-Hindi-English-Facebook-Posts/blob/main/ML%20Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Gm5Frn5ov1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9cb58ad-22e1-4b0e-9a0e-99be0c9838a5"
      },
      "source": [
        "!pip install emoji\n",
        "!pip install emojis\n",
        "!pip install -U nltk\n",
        "!pip install emosent-py\n",
        "!pip install profanity-check\n",
        "!pip install torch==1.3.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install inltk\n",
        "!pip install indic-nlp-library"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.2MB/s \n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-1.2.0\n",
            "Collecting emojis\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/94/61025e53488acd95b49862ec854e05b036f92fe9d0e512ca551a5a8b03d6/emojis-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: emojis\n",
            "Successfully installed emojis-0.6.0\n",
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.2\n",
            "Collecting emosent-py\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d7/00c5117b7f81c53d764520e0a5032e678f1b3e54daee60308a9bfe6a94d9/emosent-py-0.1.6.tar.gz\n",
            "Building wheels for collected packages: emosent-py\n",
            "  Building wheel for emosent-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emosent-py: filename=emosent_py-0.1.6-cp37-none-any.whl size=28503 sha256=8b9cf2e173f1ed3da197668fc9d0d38af7c207a64430e1c210a9941c604ce5e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/32/3c/2e21c3622b77cdc89a38a711240588ac3cf9b8e805eed0f6e1\n",
            "Successfully built emosent-py\n",
            "Installing collected packages: emosent-py\n",
            "Successfully installed emosent-py-0.1.6\n",
            "Collecting profanity-check\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/dd/bdbfe61f11b328a583960ece9145a3e080082475f52f9f56795b22ab4c41/profanity_check-1.0.3-py3-none-any.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from profanity-check) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.0.1)\n",
            "Installing collected packages: profanity-check\n",
            "Successfully installed profanity-check-1.0.3\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.3.1+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.3.1%2Bcpu-cp37-cp37m-linux_x86_64.whl (111.8MB)\n",
            "\u001b[K     |████████████████████████████████| 111.8MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.3.1+cpu) (1.19.5)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.3.1+cpu which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.3.1+cpu which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed torch-1.3.1+cpu\n",
            "Collecting inltk\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/cc/942b7e86043dc9caa3ea967665b30b84527f2a163aaf3f7d14d9afcd7d1a/inltk-0.9-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from inltk) (3.2.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.7/dist-packages (from inltk) (1.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from inltk) (4.6.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from inltk) (1.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from inltk) (7.1.2)\n",
            "Collecting async-timeout>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from inltk) (3.13)\n",
            "Collecting fastai==1.0.57\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/e2/42342ded0385d694e3250e74f43f0dc9a3ff3d5c2241a2ddd98236b5f9de/fastai-1.0.57-py3-none-any.whl (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from inltk) (2.7.3)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from inltk) (2.2.4)\n",
            "Collecting aiohttp>=3.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.5MB/s \n",
            "\u001b[?25hCollecting typing\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/d9/6eebe19d46bd05360c9a9aae822e67a80f9242aabbfc58b641b957546607/typing-3.7.4.3.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from inltk) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from inltk) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from inltk) (1.1.5)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from inltk) (7.352.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from inltk) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from inltk) (20.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (0.10.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.57->inltk) (0.9.1+cu101)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.57->inltk) (1.3.1+cpu)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (56.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.1.3)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (3.7.4.3)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 22.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (20.3.0)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->inltk) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->inltk) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->inltk) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->inltk) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->inltk) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->inltk) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->inltk) (3.4.1)\n",
            "Building wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-cp37-none-any.whl size=26308 sha256=bb8cc9f928932f891e00e822f86706f9581fd99303fef5ef7e6bea94d7fc05ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/04/41/8e1836e79581989c22eebac3f4e70aaac9af07b0908da173be\n",
            "Successfully built typing\n",
            "Installing collected packages: sentencepiece, async-timeout, fastai, multidict, yarl, aiohttp, typing, inltk\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fastai-1.0.57 inltk-0.9 multidict-5.1.0 sentencepiece-0.1.95 typing-3.7.4.3 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Installing collected packages: morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3THB5RjtXESO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5135735d-d09d-4d54-c70b-8d4350cc88da"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import re\n",
        "from emoji import UNICODE_EMOJI\n",
        "import emojis\n",
        "from emosent import get_emoji_sentiment_rank\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "from profanity_check import predict, predict_prob\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from inltk import inltk\n",
        "from inltk.inltk import setup\n",
        "from inltk.inltk import tokenize\n",
        "from nltk.util import ngrams\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "from indicnlp import common\n",
        "\n",
        "from indicnlp import loader\n",
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import accuracy_score as acs\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx2JTKeH8VEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72173a21-0755-4d23-caa1-4c7ccbe1f62d"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/TrigonaMinima/HinglishNLP.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'indic_nlp_resources' already exists and is not an empty directory.\n",
            "fatal: destination path 'indic_nlp_library' already exists and is not an empty directory.\n",
            "fatal: destination path 'HinglishNLP' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vkAX-008aDI"
      },
      "source": [
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=r\"indic_nlp_resources\"\n",
        "\n",
        "# Add library to Python path\n",
        "sys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))\n",
        "\n",
        "# Set environment variable for resources folder\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFS3bf0_WrCs"
      },
      "source": [
        "#Import all the csv files\n",
        "\n",
        "hindi_train_df = pd.read_csv(\"agr_hi_train.csv\", header= None) # 12000 rows × 3 columns\n",
        "hindi_test_df = pd.read_csv(\"agr_hi_fb_test.csv\", header = None) #970 rows × 2 columns\n",
        "hindi_validation_df = pd.read_csv(\"agr_hi_dev.csv\", header = None) #3001 rows × 3 columns\n",
        "hindi_surprise_df = pd.read_csv(\"agr_hi_sm_test.csv\", header = None) #1194 rows × 2 columns\n",
        "\n",
        "english_train_df = pd.read_csv(\"agr_en_train.csv\", header = None) #11999 rows × 3 columns\n",
        "english_test_df = pd.read_csv(\"agr_en_fb_test.csv\", header = None) #916 rows × 2 columns\n",
        "english_validation_df = pd.read_csv(\"agr_en_dev.csv\", header = None) #3001 rows × 3 columns\n",
        "english_surprise_df = pd.read_csv(\"agr_en_sm_test.csv\", header = None) #1257 rows × 2 columns\n",
        "\n",
        "#what is the _fb_gold, and tw_gold data sets?\n",
        "english_fb_gold = pd.read_csv(\"agr_en_fb_gold.csv\", header = None) #916 rows × 3 columns\n",
        "english_tw_gold = pd.read_csv(\"agr_en_tw_gold.csv\", header = None) #1257 rows × 3 columns\n",
        "hindi_fb_gold =  pd.read_csv(\"agr_hi_fb_gold.csv\", header = None) #970 rows × 3 columns\n",
        "hindi_tw_gold = pd.read_csv(\"agr_hi_tw_gold.csv\", header = None) #1194 rows × 3 columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7cOoHD9YsW8"
      },
      "source": [
        "#Combine train, validation and fb_gold sets into one for hindi and english separately\n",
        "hindi_total = pd.concat([hindi_train_df, hindi_validation_df, hindi_fb_gold])\n",
        "english_total = pd.concat([english_train_df, english_validation_df, english_fb_gold])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2ptWgF5vv7o"
      },
      "source": [
        "#Cleaning the texts\n",
        "def cleaner(df, set_language):\n",
        "  df = df.rename(columns={1: \"text\", 2: \"agression\"})\n",
        "  if set_language == \"Hindi\":\n",
        "    loader.load()\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: ItransTransliterator.to_itrans(str(x), 'hi'))\n",
        "\n",
        "  #remove html tags\n",
        "  df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(\"\\n\",\" \", x))\n",
        "  #remove urls\n",
        "  df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
        "\n",
        "  if set_language == \"English\":\n",
        "    df['tokenized'] = df[\"text\"].apply(lambda x: nltk.WordPunctTokenizer().tokenize(x))\n",
        "  if set_language == \"Hindi\":\n",
        "    df['tokenized'] = df[\"text\"].apply(lambda x: nltk.WordPunctTokenizer().tokenize(str(x)))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlsSAVxGxcl4"
      },
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "#returns numerical features related to emojis including emoji_sentiment, number \n",
        "#of emojis, probability of profanity, negativity score, neutraility score,\n",
        "#positivity score, compound score as well as returns an array of 5grams\n",
        "def average_emoji_sentiment(text):\n",
        "  sentiment = 0\n",
        "  emojis_in_list = emojis.get(text)\n",
        "  number_of_emojis = len(emojis_in_list)\n",
        "  for i in emojis_in_list:\n",
        "    try:\n",
        "      sentiment += get_emoji_sentiment_rank(i)[\"sentiment_score\"]\n",
        "    except KeyError:\n",
        "      #cases where the emosentpy package is a little old for some emojis - \n",
        "      #only 4 in the whole dataset\n",
        "      pass\n",
        "  if number_of_emojis == 0:\n",
        "    emoji_sentiment = 0.5\n",
        "  else:\n",
        "    emoji_sentiment = sentiment / number_of_emojis\n",
        "  #using the profanity_check pacakage - https://pypi.org/project/profanity-check/\n",
        "  profanity_prob = predict_prob([text])\n",
        "  pols = sia.polarity_scores(text)\n",
        "  neg_score = pols.get('neg')\n",
        "  neutral_score = pols.get('neu')\n",
        "  pos_score = pols.get('pos')\n",
        "  compound_score = pols.get('compound')\n",
        "  #creating 5-grams\n",
        "  x = text.lower()\n",
        "  x = re.sub(r'[^a-zA-Z0-9\\s]', ' ', x)\n",
        "  tokens = [char for char in x]\n",
        "  ngram = list(ngrams(tokens, 5))\n",
        "  ngram = [''.join(i) for i in ngram]\n",
        "  return emoji_sentiment, number_of_emojis, profanity_prob[0], neg_score, neutral_score, pos_score, compound_score, ngram\n",
        "\n",
        "#returns numerical features for each post such as number of punctuation per word,\n",
        "# number of exclaimatory punctuations, number of hashtags, number of numbers and \n",
        "# number of capital words\n",
        "def features(tokens):\n",
        "  total_words = len(tokens)\n",
        "  punctuations = 0\n",
        "  exclaim = 0\n",
        "  num_numbers = 0\n",
        "  hashtags = 0\n",
        "  capital_words = 0\n",
        "  #string.punctuation = !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
        "  exclamatory_puncs = ['!','?']\n",
        "  for i in tokens:\n",
        "    if i in string.punctuation:\n",
        "      punctuations = punctuations + 1\n",
        "    if i in exclamatory_puncs:\n",
        "      exclaim += 1\n",
        "    if \"#\" in i:\n",
        "      hashtags += 1\n",
        "    if i.isupper():\n",
        "      capital_words += 1\n",
        "    num_numbers += sum(c.isdigit() for c in i)\n",
        "  if total_words == 0:\n",
        "    return 0, 0, 0, 0, 0\n",
        "  punc_per_word = punctuations/total_words\n",
        "  exclaim_per_word = exclaim/total_words\n",
        "  return punc_per_word, exclaim_per_word, hashtags, num_numbers, capital_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVfFsiTmAgYu"
      },
      "source": [
        "#Feature Extraction\n",
        "def feature_extractor (df, lang):\n",
        "  #extract emoji features from average_emoji_sentiment and make columns for each\n",
        "  df['tempcol'] = df['text'].apply(lambda x: average_emoji_sentiment(x))\n",
        "  new_col_list = ['emoji_sentiment', 'number_of_emojis', 'profanity_prob', 'neg_score', 'neutral_score', 'pos_score', 'compound_score', 'ngram_5']\n",
        "  for n,col in enumerate(new_col_list):\n",
        "    df[col] = df['tempcol'].apply(lambda tempcol: tempcol[n])\n",
        "  df = df.drop('tempcol',axis=1)\n",
        "\n",
        "  #extract other features and make columns for each feature\n",
        "  df['temp_column'] = df['tokenized'].apply(lambda x: features(x))\n",
        "  new_col_list = ['punc_per_word','exclamation_punc_per_word','hashtags','num_numbers', 'num_capital_words']\n",
        "  for n,col in enumerate(new_col_list):\n",
        "    df[col] = df['temp_column'].apply(lambda temp_column: temp_column[n])\n",
        "  df = df.drop('temp_column',axis=1)\n",
        "\n",
        "  df['num_words_in_post'] = df['tokenized'].apply(lambda x: len(x))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL6lUr4O_Mr_"
      },
      "source": [
        "def filter_stopwords (df, lang):\n",
        "  if lang == \"English\":\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "  if lang == \"Hindi\":\n",
        "    filter_stop_words = []\n",
        "    myfile = open(\"/content/HinglishNLP/data/assets/stop_hinglish\", \"r\")\n",
        "    myline = myfile.readline()\n",
        "    while myline:\n",
        "      l = str(myline).split('\\n')[0]\n",
        "      filter_stop_words.append(l)\n",
        "      myline = myfile.readline()\n",
        "    myfile.close()  \n",
        "    stop_words = set(filter_stop_words)\n",
        "  def filter_punc_stopwords_numbers(tokens):\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tokens = [w for w in tokens if w.isalpha()]\n",
        "    return tokens\n",
        "  df['filtered_tokenized'] = df['tokenized'].apply(lambda x: filter_punc_stopwords_numbers(x))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg1ndM8gAWjN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "fd07ae85-31f5-4b7c-ff3c-98cbbcc2b9af"
      },
      "source": [
        "#Clean the text\n",
        "english_total = cleaner(english_total, \"English\")\n",
        "hindi_total = cleaner(hindi_total, \"Hindi\")\n",
        "\n",
        "#Extract features\n",
        "english_total = feature_extractor(english_total, \"English\")\n",
        "hindi_total = feature_extractor(hindi_total, \"Hindi\")\n",
        "\n",
        "#Filter Stop Words\n",
        "english_total = filter_stopwords(english_total, \"English\")\n",
        "hindi_total = filter_stopwords(hindi_total, \"Hindi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f8e460ce8071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Clean the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menglish_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"English\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhindi_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhindi_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Hindi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5a14d8ef3fef>\u001b[0m in \u001b[0;36mcleaner\u001b[0;34m(df, set_language)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mset_language\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Hindi\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mItransTransliterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_itrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#remove html tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5a14d8ef3fef>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mset_language\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Hindi\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mItransTransliterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_itrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#remove html tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/indicnlp/transliterate/unicode_transliterate.py\u001b[0m in \u001b[0;36mto_itrans\u001b[0;34m(text, lang_code)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\u0d7f'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\u0d15\\u0d4d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0misc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m### naive lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/indicnlp/transliterate/unicode_transliterate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\u0d7f'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\u0d15\\u0d4d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0misc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m### naive lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/indicnlp/script/indic_scripts.py\u001b[0m in \u001b[0;36mget_offset\u001b[0;34m(c, lang)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_supported_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndicNlpException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Language {}  not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCRIPT_RANGES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/indicnlp/script/indic_scripts.py\u001b[0m in \u001b[0;36mis_supported_language\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_supported_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCRIPT_RANGES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqY8yUDA-DT3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "20404a45-8e8c-4cf2-cc7a-f7cf1e4646a1"
      },
      "source": [
        "hindi_total.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emoji_sentiment</th>\n",
              "      <th>number_of_emojis</th>\n",
              "      <th>profanity_prob</th>\n",
              "      <th>neg_score</th>\n",
              "      <th>neutral_score</th>\n",
              "      <th>pos_score</th>\n",
              "      <th>compound_score</th>\n",
              "      <th>punc_per_word</th>\n",
              "      <th>exclamation_punc_per_word</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>num_numbers</th>\n",
              "      <th>num_capital_words</th>\n",
              "      <th>num_words_in_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>1.597100e+04</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "      <td>15971.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.483984</td>\n",
              "      <td>0.104251</td>\n",
              "      <td>2.410853e-01</td>\n",
              "      <td>0.014603</td>\n",
              "      <td>0.964874</td>\n",
              "      <td>0.020209</td>\n",
              "      <td>0.011839</td>\n",
              "      <td>0.056592</td>\n",
              "      <td>0.003733</td>\n",
              "      <td>0.052282</td>\n",
              "      <td>1.320205</td>\n",
              "      <td>0.502786</td>\n",
              "      <td>33.859182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.087363</td>\n",
              "      <td>0.539569</td>\n",
              "      <td>2.070749e-01</td>\n",
              "      <td>0.054237</td>\n",
              "      <td>0.091231</td>\n",
              "      <td>0.070924</td>\n",
              "      <td>0.234215</td>\n",
              "      <td>0.077568</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.460958</td>\n",
              "      <td>7.806996</td>\n",
              "      <td>3.148174</td>\n",
              "      <td>59.838222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.478170e-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.980500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.129089e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.599436e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.974237e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.787000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.997200</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>1119.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emoji_sentiment  number_of_emojis  ...  num_capital_words  num_words_in_post\n",
              "count     15971.000000      15971.000000  ...       15971.000000       15971.000000\n",
              "mean          0.483984          0.104251  ...           0.502786          33.859182\n",
              "std           0.087363          0.539569  ...           3.148174          59.838222\n",
              "min          -1.000000          0.000000  ...           0.000000           0.000000\n",
              "25%           0.500000          0.000000  ...           0.000000          12.000000\n",
              "50%           0.500000          0.000000  ...           0.000000          19.000000\n",
              "75%           0.500000          0.000000  ...           0.000000          34.000000\n",
              "max           1.000000         18.000000  ...         107.000000        1119.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09HR2bstLTyf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "7e6bc913-7312-467c-9218-2f189015421a"
      },
      "source": [
        "english_total.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emoji_sentiment</th>\n",
              "      <th>number_of_emojis</th>\n",
              "      <th>profanity_prob</th>\n",
              "      <th>neg_score</th>\n",
              "      <th>neutral_score</th>\n",
              "      <th>pos_score</th>\n",
              "      <th>compound_score</th>\n",
              "      <th>punc_per_word</th>\n",
              "      <th>exclamation_punc_per_word</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>num_numbers</th>\n",
              "      <th>num_capital_words</th>\n",
              "      <th>num_words_in_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>1.591600e+04</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "      <td>15916.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.487240</td>\n",
              "      <td>0.098643</td>\n",
              "      <td>1.396394e-01</td>\n",
              "      <td>0.099736</td>\n",
              "      <td>0.772495</td>\n",
              "      <td>0.125060</td>\n",
              "      <td>0.039535</td>\n",
              "      <td>0.078978</td>\n",
              "      <td>0.010130</td>\n",
              "      <td>0.032609</td>\n",
              "      <td>1.099648</td>\n",
              "      <td>1.151294</td>\n",
              "      <td>28.335134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.078305</td>\n",
              "      <td>0.658215</td>\n",
              "      <td>1.448667e-01</td>\n",
              "      <td>0.144912</td>\n",
              "      <td>0.194910</td>\n",
              "      <td>0.160439</td>\n",
              "      <td>0.491968</td>\n",
              "      <td>0.074963</td>\n",
              "      <td>0.034051</td>\n",
              "      <td>0.274600</td>\n",
              "      <td>6.833489</td>\n",
              "      <td>9.065668</td>\n",
              "      <td>44.060324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.806942e-13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.999900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.245075e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.668000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.318200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000732e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.789000</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.529708e-01</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.196000</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9.986500e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>551.000000</td>\n",
              "      <td>748.000000</td>\n",
              "      <td>1476.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emoji_sentiment  number_of_emojis  ...  num_capital_words  num_words_in_post\n",
              "count     15916.000000      15916.000000  ...       15916.000000       15916.000000\n",
              "mean          0.487240          0.098643  ...           1.151294          28.335134\n",
              "std           0.078305          0.658215  ...           9.065668          44.060324\n",
              "min          -0.400000          0.000000  ...           0.000000           0.000000\n",
              "25%           0.500000          0.000000  ...           0.000000          12.000000\n",
              "50%           0.500000          0.000000  ...           0.000000          18.000000\n",
              "75%           0.500000          0.000000  ...           1.000000          31.000000\n",
              "max           1.000000         16.000000  ...         748.000000        1476.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JjqlkjHCJf6"
      },
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "def lemmatizing(tokens):\n",
        "  return [wn.lemmatize(w) for w in tokens]\n",
        "\n",
        "english_total['lemmatized_tokens'] = english_total['filtered_tokenized'].apply(lambda x: lemmatizing(x))\n",
        "hindi_total['lemmatized_tokens'] = hindi_total['filtered_tokenized'].apply(lambda x: lemmatizing(x))\n",
        "#making text lowercase for use in the vectorizer\n",
        "english_total['lower_case_text'] = english_total['text'].apply(lambda x: x.lower())\n",
        "hindi_total['lower_case_text'] = hindi_total['text'].apply(lambda x: x.lower())\n",
        "#making lemmatized tokens into string for tfidf vectorizer\n",
        "english_total['lemmatized_text']=english_total['lemmatized_tokens'].apply(lambda x: \" \".join(x))\n",
        "hindi_total['lemmatized_text']=hindi_total['lemmatized_tokens'].apply(lambda x: \" \".join(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYeKpC8b4KR8"
      },
      "source": [
        "#word cloud of most common words in English dataset\n",
        "text_CAG = english_total['lemmatized_tokens'][english_total.index[english_total.agression == \"CAG\"]].apply(lambda x: \" \".join(x)).str.cat(sep='')\n",
        "text_OAG = english_total['lemmatized_tokens'][english_total.index[english_total.agression == \"OAG\"]].apply(lambda x: \" \".join(x)).str.cat(sep='')\n",
        "text_NAG = english_total['lemmatized_tokens'][english_total.index[english_total.agression == \"NAG\"]].apply(lambda x: \" \".join(x)).str.cat(sep='')\n",
        "\n",
        "# word cloud image for CAG:\n",
        "wordcloud = WordCloud().generate(text_CAG)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "#word cloud image for OAG\n",
        "wordcloud = WordCloud().generate(text_OAG)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "#word cloud image for NAG\n",
        "wordcloud = WordCloud().generate(text_NAG)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJm27yeNEWtt"
      },
      "source": [
        "#word cloud of most common words in Hindi\n",
        "text_CAG = hindi_total['lemmatized_tokens'][hindi_total.index[hindi_total.agression == \"CAG\"]].apply(lambda x: \" \".join(x)).str.cat(sep='')\n",
        "text_OAG = hindi_total['lemmatized_tokens'][hindi_total.index[hindi_total.agression == \"OAG\"]].apply(lambda x: \" \".join(x)).str.cat(sep='')\n",
        "text_NAG = hindi_total['lemmatized_tokens'][hindi_total.index[hindi_total.agression == \"NAG\"]].apply(lambda x: \" \".join(x)).str.cat(sep='')\n",
        "\n",
        "# word cloud image for CAG:\n",
        "wordcloud = WordCloud().generate(text_CAG)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "#word cloud image for OAG\n",
        "wordcloud = WordCloud().generate(text_OAG)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "#word cloud image for NAG\n",
        "wordcloud = WordCloud().generate(text_NAG)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY5IDh_NPdXt"
      },
      "source": [
        "#ENGLISH: Using Tfidf Vectorizer on lemmatized and filtered word tokenization and combining that with features that were extracted above \n",
        "\n",
        "X = english_total[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post',\n",
        " 'lemmatized_text'\n",
        "]]\n",
        "y = english_total['agression']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "#TFIDF Vectorizer\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect_fit = tfidf_vect.fit(X_train['lemmatized_text'])\n",
        "\n",
        "tfidf_train = tfidf_vect_fit.transform(X_train['lemmatized_text'])\n",
        "tfidf_test = tfidf_vect_fit.transform(X_test['lemmatized_text'])\n",
        "\n",
        "X_train_vect_en = pd.concat([X_train[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
        "X_test_vect_en = pd.concat([X_test[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9c92yOCL1U"
      },
      "source": [
        "#TFIDF Vectorizer for Hindi\n",
        "\n",
        "X_hi = hindi_total[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post',\n",
        " 'lemmatized_text'\n",
        "]]\n",
        "y_hi = hindi_total['agression']\n",
        "X_train_hi, X_test_hi, y_train_hi, y_test_hi = train_test_split(X_hi,y_hi, test_size=0.2, random_state=42)\n",
        "\n",
        "tfidf_vect_hi = TfidfVectorizer()\n",
        "tfidf_vect_fit_hi = tfidf_vect_hi.fit(X_train_hi['lemmatized_text'])\n",
        "\n",
        "tfidf_train_hi = tfidf_vect_fit_hi.transform(X_train_hi['lemmatized_text'])\n",
        "tfidf_test_hi = tfidf_vect_fit_hi.transform(X_test_hi['lemmatized_text'])\n",
        "\n",
        "X_train_vect_hi = pd.concat([X_train_hi[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_train_hi.toarray())], axis=1)\n",
        "X_test_vect_hi = pd.concat([X_test_hi[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_test_hi.toarray())], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a61rsHJMDQMH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "2c35a3a0-6591-4eda-e016-c4980163c60b"
      },
      "source": [
        "#English\n",
        "\n",
        "#Train Random Forest Classifier using gridsearch for optimization\n",
        "n_estimators = [150, 300]\n",
        "max_depth = [30, 50]\n",
        "min_samples_split = [5, 10, 15]\n",
        "min_samples_leaf = [1, 5, 10] \n",
        "\n",
        "forest = RandomForestClassifier(n_jobs = -1)\n",
        "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth)\n",
        "gridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1)\n",
        "bestF = gridF.fit(X_train_vect_en, y_train)\n",
        "pd.DataFrame(bestF.cv_results_).sort_values('rank_test_score')\n",
        "\n",
        "#Hindi\n",
        "'''forest_hi = RandomForestClassifier()\n",
        "gridF_hi = GridSearchCV(forest_hi, hyperF, cv = 3, verbose = 1, \n",
        "                      n_jobs = -1)\n",
        "bestF_hi = gridF.fit(X_train_vect, y_train)\n",
        "pd.DataFrame(bestF_hi.cv_results_).sort_values('rank_test_score')\n",
        "\n",
        "#find what each of the best ones are '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5b428006690d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mhyperF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgridF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbestF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdtwanjdDeGY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "0577a2dd-2ff6-4819-b5c6-edf1fb480f14"
      },
      "source": [
        "#train random forest models using the best parameters for English\n",
        "rf_en = RandomForestClassifier(n_estimators= 400, max_depth = 50, n_jobs = -1) ##PARAMS BASED ON OPTIMIZATION ABOVE\n",
        "rf_model_en = rf_en.fit(X_train_vect_en, y_train)\n",
        "y_pred_train = rf_model_en.predict(X_train_vect_en)\n",
        "y_pred_test = rf_model_en.predict(X_test_vect_en)\n",
        "\n",
        "#English training data matrix\n",
        "\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5gUVdbH8e8PhpxzRlQwu6KgooBrxJwT6Cqr7GLcNbzqimFRjGvArCtGMIGYXSOiqBgIAoKiBEUlSJCcYWbO+0fdGXtwQjNMT/cU5+NTz3TdSrfK4fSdU7duycxwzjlX8VVKdwWcc86VDQ/ozjkXEx7QnXMuJjygO+dcTHhAd865mPCA7pxzMeEB3W0xSTUkvSlpuaThW7CfMyW9X5Z1SwdJ70jqne56uK2PB/StiKQzJI2XtErSryHwdCuDXZ8CNAMamdmppd2JmT1nZj3KoD4FSDpQkkl6dZPyPUL5qCT3c4OkZ0taz8yONLPBpayuc6XmAX0rIely4F7gVqLg2xZ4GDi+DHa/DTDdzLLLYF+psgjYT1KjhLLewPSyOoAi/m/KpY3/8m0FJNUDBgAXmdkrZrbazDaa2ZtmdmVYp5qkeyXNC9O9kqqFZQdKmiPp/yQtDK37c8KyG4F/A6eHln+fTVuyktqFlnBWmP+rpB8lrZQ0S9KZCeWjE7bbX9K4kMoZJ2n/hGWjJN0k6bOwn/clNS7mMmwAXgN6hu0rA6cDz21yre6TNFvSCklfSeoeyo8Arkk4z68T6nGLpM+ANcB2oexvYfkjkl5O2P9/JI2UpKT/BzqXJA/oW4f9gOrAq8Wscy3QBegI7AHsA1yXsLw5UA9oBfQBHpLUwMz6E7X6h5lZbTN7oriKSKoF3A8caWZ1gP2BSYWs1xB4K6zbCBgIvLVJC/sM4BygKVAVuKK4YwNDgLPD58OBb4B5m6wzjugaNASeB4ZLqm5m725ynnskbHMW0BeoA/y8yf7+D9g9fFl1J7p2vc3H3HAp4AF969AI+K2ElMiZwAAzW2hmi4AbiQJVno1h+UYzextYBexYyvrkArtJqmFmv5rZt4WsczQww8yeMbNsM3sB+B44NmGdp8xsupmtBV4kCsRFMrPPgYaSdiQK7EMKWedZM1scjnk3UI2Sz/NpM/s2bLNxk/2tIbqOA4FngX+Y2ZwS9udcqXhA3zosBhrnpTyK0JKCrcufQ1n+Pjb5QlgD1N7cipjZaqJUx/nAr5LekrRTEvXJq1OrhPn5pajPM8DFwEEU8heLpCskfRfSPMuI/iopLpUDMLu4hWY2BvgRENEXj3Mp4QF96/AFsB44oZh15hHd3MzTlj+mI5K1GqiZMN88caGZvWdmhwEtiFrdjyVRn7w6zS1lnfI8A1wIvB1az/lCSuQq4DSggZnVB5YTBWKAotIkxaZPJF1E1NKfF/bvXEp4QN8KmNlyohuXD0k6QVJNSVUkHSnpjrDaC8B1kpqEm4v/JkoRlMYk4ABJbcMN2X55CyQ1k3R8yKWvJ0rd5Bayj7eBHUJXyyxJpwO7AP8rZZ0AMLNZwJ+J7hlsqg6QTdQjJkvSv4G6CcsXAO02pyeLpB2Am4G/EKVerpJUbGrIudLygL6VCPngy4ludC4iShNcTNTzA6KgMx6YDEwBJoSy0hxrBDAs7OsrCgbhSqEe84AlRMH1gkL2sRg4huim4mKilu0xZvZbaeq0yb5Hm1lhf328B7xL1JXxZ2AdBdMpeQ9NLZY0oaTjhBTXs8B/zOxrM5tB1FPmmbweRM6VJfnNdueciwdvoTvnXEx4QHfOuZjwgO6cczHhAd0552KiuAdN0mr6zkf43doUu33tZj8X5DbTkHlfpLsKW4XsDXO3eGycjb/9mHTMqdJ4u4wci8db6M45FxMZ20J3zrlylZuT7hpsMQ/ozjkHkJPJw/knxwO6c84BZoWNQFGxeEB3zjmAXA/ozjkXD95Cd865mPCbos45FxPeQnfOuXgw7+XinHMx4TdFnXMuJjzl4pxzMeE3RZ1zLia8he6cczERg5uiPtqic85BdFM02akEkn6SNEXSJEnjQ1lDSSMkzQg/G4RySbpf0kxJkyXtlbCf3mH9GZJ6l3RcD+jOOQeY5SQ9JekgM+toZp3D/NXASDPrAIwM8wBHAh3C1Bd4BKIvAKA/sC+wD9A/70ugKB7QnXMOohx6slPpHA8MDp8HAycklA+xyJdAfUktgMOBEWa2xMyWAiOAI4o7gAd055yDzUq5SOoraXzC1HeTvRnwvqSvEpY1M7Nfw+f5QLPwuRUwO2HbOaGsqPIi+U1R55yDzWp5m9kgYFAxq3Qzs7mSmgIjJH2/yfYmqcxfs+ktdOecA8jZmPxUAjObG34uBF4lyoEvCKkUws+FYfW5QJuEzVuHsqLKi+QB3TnnoMx6uUiqJalO3megB/AN8AaQ11OlN/B6+PwGcHbo7dIFWB5SM+8BPSQ1CDdDe4SyInnKxTnnoCwfLGoGvCoJohj7vJm9K2kc8KKkPsDPwGlh/beBo4CZwBrgHAAzWyLpJmBcWG+AmS0p7sAe0J1zDspscC4z+xHYo5DyxcAhhZQbcFER+3oSeDLZY3tAd8458NEWnXMuLiyJm52ZzgO6c86BD87lnHOx4SkX55yLCW+hO+dcTHgL3TnnYsJb6M45FxPZFf8FFx7Qi5HVvDHNb7+Syo3qA7D8xbdZ9szrVN1xW5rd8E8q1azOxrkLmH/lHeSuXkNWy2a0e2sQG2bNAWDd19+z8MYHop1VyaLpdRdSc58/Qa7x271Ps2rEZ+k6tYxyzh0XssfBnVixeDn/PvxyAE68vCcdD9sbs1xW/LaCJ694kGULl3JE3+PockJ3ACpVrkzL9q24ZK8+1GlUl/MfvCx/n03aNOO1e4Yx4sm30nJOFUW1atUY9eHLVK1WjaysyrzyylvcOOBuBj16F5067YEEM2bM4tw+l7J69Zp0Vze1YtBCV/SQUuaZvvMRaa9Y5SYNyWrSkPVTZ6KaNdjm5QeYd/EAmt92BYvufIy146ZQ96QeVGndnMX3DyGrZTNa/fdGfj7u/D/sq9HFf4HKlVl832CQqFSvDrnLVqThrH53+9raaT1+nh322Zl1q9fxt4H/yA/o1WvXYN2qtQAc+tejaNGhNc9cW3Bwuz0O6USPPsdw5xk3FihXpUoMHPMoN5/Qj8VzfyufkyjCkHlfpPX4yahVqyarV68hKyuLT0a9ymWX92fqd9NZuXIVAHfd0Z+Fi37jjjsfSnNNi5a9Ya62dB9r37gr6ZhT47grtvh4qeCDcxUjZ9ES1k+dCYCtWcuGH2aT1awRVdq1Yu24KQCs+XwCtQ/rWuK+6p50OEsGDY1mzNIezDPJ9LHfsXr5qgJlecEcoGrNalBIw2Pf47ox5o0//pWzS9fdWfjzgrQH84oir+VdpUoWWVWqYGb5wRygeo3qZGrDr0yl/gUXKecBPUlZLZtRbeftWff1NDbM/Jlah+wHQO3DD6BKiyb561Vp1Zy2Lz9I6yF3UKPTrgBUqlMLgMb/7E3blx+kxT3X5qdxXNFOuqIXd33+X7oc353XBg4rsKxq9ars9ueOfPXOl3/Ybp9juzLmjdHlVc0Kr1KlSowf9z6/zp3MyJGfMHbcRAAef2wgc2dPYqcd2/PgQ0kPJ1JxleE7RdMlJQFdUmtJ3RLmL5f07zC1T8UxU0k1q9Py/utYdPuj5K5ew/xrB1K/1zG0fekBKtWqgW2MbqbkLFrCj4ecxS8nX8yi2wfR/M6rqVSrJlSuTJUWTVg7cSq/nHwxayd9R5Or/p7ms8p8r9z1Alfsfz5fvv4pB/cu+OatPQ7tzMzx0/7Qsq9cJYuOh3Zm/NuZn+rIFLm5uXTeuwfbbNuZvTvvya677gjA3/5+OW222Yvvvp/Baacel+ZalgNvoRfpTiCxCXoesJrotUw3FroFFHit07Bls4tarXxlVablfdez4s2P8m9ibpw1h7l/u5ZfTvkHK98excZfordK2caN5C5bCcD6qTPZOPtXqrRrRe6yFeSuWZe//ar3PqHaLhXuey1tvnztUzod0aVA2b5FtMJ3P3BPfv5mFit+W15e1YuN5ctXMOrjzzi8x4H5Zbm5ubz44uucdOLR6atYecnOTn7KUKkK6Dua2f8S5teY2d1mdhPQtqiNzGyQmXU2s86n129T1GrlqvnNl7Hhx19YNviV/LLKDetFHyQand+LZcOinhSVG9SDStElrdK6OVW3acnGOVGwXzXqS2rs8ycAanbZkw0zfynHs6h4mrZrnv95z8P2Zv4Pv7+opUadmuyw7y5MHDHuD9vte1w3xr7p6ZZkNW7ckHr16gJQvXp1Dj3kAKZP/5Htt2+Xv86xx/Rg2rSZaaphOTJLfspQqeq2WH2T+cQxgBun6Jhlrvpeu1L3+ENZP20WbV+J7vAvvvdpqmzTkvpnHAvAqhGfseKV9wGo0Xk3Gv3z7CgFY8aCGx4gN6QEfrv7SZr/50oq9zufnCXLmH/twPScVAY67/5L2bHLrtRuUIe7vniU1+8Zxu4H7UXz7VpiucbiuYsYktDDZa/D9+HbTyezYe36AvupWqMau3b7E0OuebS8T6HCatGiGU8+cS+VK1eiUqVKvPTSm7z19gd8/NGr1KlbG0lMnjyViy7ul+6qpl4G58aTlZJui5LGAGeZ2fRNyncChpjZPiXtIxO6LcZdpnRbjLOK0G0xDsqk2+Jz1yffbfHMmzKy22KqWuj9gf9JugWYEMo6AdcAl6TomM45V3oZfLMzWSkJ6OH9eScBVwH/DMXfAieZ2TepOKZzzm2RnJx012CLpezR/xC4z04sk9RG0pVmdmeqjuucc6USgxx6ysdykdQEOBXoBbQEXk31MZ1zbrN5QC+cpDrAScAZwA7AK8C2ZtY6Fcdzzrkt5jn0Ii0ExgLXAaPNzCSdmKJjOefcFrPcit+xLlUPFvUDqgEPA/0kbZ+i4zjnXNnwsVwKZ2b3mlkX4PhQ9BrQUtJVknZIxTGdc26L5OQkP2WoVA3O1V5SVzP70cxuNbPdgb2BI4DvUnFM55zbIt5CL9K9QIEBv81sCnAp8E6Kjumcc6UXg4CeqpuizUIAL8DMJkvaJkXHdM650svgQbeSlaqAXtzbG2qk6JjOOVd6GdzyTlaqUi7jJf3hDQ6S/gZ8laJjOudc6eVa8lOGSlUL/VLgVUln8nsA7wxUBbw/unMu82Rw75Vkparb4gIz25/o7UQ/helGM9vPzOan4pjOObclLDc36SkZkipLmijpf2F+W0ljJM2UNExS1VBeLczPDMvbJeyjXyifJunwko6Z0pdEm9lHZvZAmD5M5bGcc26LlH3K5RIKdtP+D3CPmbUHlgJ9QnkfYGkovyesh6RdgJ7ArkRdvh+WVLm4A6Y0oDvnXIVRhi+JltQaOBp4PMwLOBh4KawyGDghfD4+zBOWHxLWPx4YambrzWwWMBMo9uVAHtCdcw42q4We+EL7MPXdZG/3Er0PIi/6NwKWmVneG6bnAK3C51bAbICwfHlYP7+8kG0KlfLhc51zrkLITv6mqJkNAgYVtkzSMcBCM/tK0oFlU7nkeEB3zjkoy+FzuwLHSToKqA7UBe4D6kvKCq3w1sDcsP5coA0wR1IWUA9YnFCeJ3GbQnnKxTnnoMxuippZPzNrbWbtiG5qfmhmZwIfAaeE1XoDr4fPb4R5wvIPzcxCec/QC2ZboAPRsORF8ha6c85B0t0Rt8C/gKGSbgYmAk+E8ieAZyTNBJYQfQlgZt9KehGYCmQDF5lZsXkhD+jOOQcpeQLUzEYBo8LnHymkl4qZrSN6TWdh298C3JLs8TygO+ccZPQj/cnygO6ccxCLR/89oDvnHPF4p6gHdOecA0+5OOdcbMRgPHQP6M45B95Cd8652PCA7pxz8WA5nnJJmV1++MM7pl0ZWzvv03RXIfaGtOye7iq4ZHkL3Tnn4sG7LTrnXFx4QHfOuZio+Cl0D+jOOQdg2RU/ontAd8458Ba6c87Fhd8Udc65uPAWunPOxYO30J1zLi68he6cc/Fg2emuwZbzgO6cc4B5C90552IizgFd0l7FbWhmE8q+Os45lx5xb6HfXcwyAw4u47o451zaxDqgm9lB5VkR55xLJ8tRuquwxSqVtIKkmpKukzQozHeQdEzqq+acc+XHcpOfMlWJAR14CtgA7B/m5wI3p6xGzjmXBparpKdMlUxA397M7gA2ApjZGiBzz8g550ohDi30ZLotbpBUg+hGKJK2B9antFbOOVfOzCp+OzWZgN4feBdoI+k5oCvw11RWyjnnylsmt7yTVWJAN7MRkiYAXYhSLZeY2W8pr5lzzpWj3Bj0ckn2SdE/A92I0i5VgFdTViPnnEuDTL7Zmaxkui0+DJwPTAG+Ac6T9FCqK+acc+WprHq5SKouaaykryV9K+nGUL6tpDGSZkoaJqlqKK8W5meG5e0S9tUvlE+TdHhJ55BMC/1gYGczy7spOhj4NontnHOuwrCyGw59PXCwma2SVAUYLekd4HLgHjMbKum/QB/gkfBzqZm1l9QT+A9wuqRdgJ7ArkBL4ANJO5hZTlEHTqbb4kygbcJ8m1DmnHOxUVYtdIusCrNVwpQ3XMpLoXwwcEL4fHyYJyw/RJJC+VAzW29ms4ji7j7FHbu4wbneDJWoA3wnaWyY3xcYW+wZOedcBbM53RYl9QX6JhQNMrNBCcsrA18B7YGHgB+AZWb5o67PAVqFz62A2VEdLFvScqBRKP8y4RiJ2xSquJTLXSWck3POxUbOZvRyCcF7UDHLc4COkuoTdSLZaYsrmITiBuf6uDwq4JxzmSAVDxaZ2TJJHwH7AfUlZYVWemuiYVQIP9sAcyRlAfWAxQnleRK3KVQyvVy6SBonaZWkDZJyJK3Y7DNzzrkMVoa9XJqEljnhKfvDgO+Aj4BTwmq9gdfD5zfCPGH5h6ETyhtAz9ALZlugAyWku5Pp5fIg0Z3W4UBn4GxghyS2c865CqMMe7m0AAaHPHol4EUz+5+kqcBQSTcDE4EnwvpPAM9ImgksIYq3mNm3kl4EpgLZwEXF9XCBJB8sMrOZkiqHnT0laSLQb7NP0znnMlRZPVhkZpOBPQsp/5FCeqmY2Trg1CL2dQtwS7LHTiagrwkd4CdJugP4leS6OzrnXIWRk1vxw1oyZ3BWWO9iYDVRkv6kVFaqInhs0N3Mm/M1kyaOzC/7z23X8c2Uj5nw1QheGv449erVTWMNK44eJ/fmxLMu4OTeF3Hauf8ssOzpF15mt65HsnTZcgA+/PQLTjz793UnfP0NAPPmL+DUcy7m5N4XcfyZ5zHs1bfK/TwqotatW/LB+8OZ/PVHfD3pQ/5xcZ/8ZRddeA7fTPmYryd9yO23XZvGWpYPs+SnTJXM4Fw/h4/rgLxHWIcBp6ewXhlvyJAXefjhp3jqqfvyyz4Y+QnXXHcbOTk53HbrNVz9r4vpd82taaxlxfHkA7fToH69AmW/LljE52Mn0KJZ0/yyLp06clC3Lkhi2sxZXHH9rbz5wmM0adSQ5x4dSNWqVVmzZi0nnHU+B3XrQtMmjcr7VCqU7OxsrrzqRiZO+obatWsxdsy7fDDyE5o1bcJxxx7OXp0OY8OGDTTZCq5jbgyGzy3t3xj7lWktKqBPR49hydJlBcpGfPAJOTnRPYsvx0ygVasW6ahabNxx/6NcfmEflPDvrGbNGigUrF23jryFVapUoWrVqgBs2LiR3ExuRmWQ+fMXMnFS9FfOqlWr+f77GbRq2ZzzzjubO+58iA0bNgCwaNHidFazXJgp6SlTlUvSSFIrSW3DlOwIjxXaOX/tybvvfZTualQIkuh72bWcdu4/GP7620CUWmnapDE7ddjuD+t/8PFnHNvr71x4xb+56ZrL8st/XbCIE8++gENPPJs+Z57qrfPNtM02rem4x26MGTuRDh22o1u3ffh89Jt8+MFLdO60R7qrl3KxTrlI2quoRURjExRJUj+gipkNCEVfAMuAqkRjFtxWxHb5j9Oqcj0qVapVbOUzVb+r/0l2djbPP/9KuqtSIQx55C6aNWnM4qXL+Pul17DtNm14bMgwBt1T+M39Q//clUP/3JXxk6bw4GNDePy+6NepRbMmvDrkERYuWsw/+w3gsIO60bhhg/I8lQqrVq2avDjsMS6/oj8rV64iK6syDRrUZ/9ux7J354688Px/6bBjvP8wj0PKpbjW8t3FLPu+hP2eCnRPmF9sZnuGfpkfU0RAT3ycNqtqqwz+Hiza2WedxtFHHcphh5+W7qpUGM2aNAagUYP6HHLA/oyfOIW58+Zzcu8LAViw6DdOPfcfDH3sXho3api/XeeOuzNn3nyWLlteIP/etEkj2m+3DRO+/oYeB3XHFS8rK4vhwx7jhRde5bXX3gFg7pxf8z+PGz+J3NxcGjduyG+/LUlnVVMqDr1cinv0/6At2bGZrU6YvS+U5YQnp2Lp8B4HcsUVF3DwISezdu26dFenQlizdh2Wm0utWjVZs3Ydn4+dwAXnnMEnbw3NX6fHyb0Z9sT9NKhfj1/mzKNNqxZIYuq0mWzYsJH69eoyf+Ei6terS/Vq1Vi+YiUTJ0/l7NNPTOOZVRyPDbqb776fyb33/T40yetvvMeBB+7PqI8/p0OH7ahatWqsgzmElyZXcKnKZ9eWVMXMNgKY2dMQDeQOxKIv37PPPMSfD9iPxo0b8tOP47lxwF3866qLqVatGu++EwWjMWMmcNHFV6e5pplt8ZKlXHLNTQDkZOdwVI8D6dalc5Hrjxg1mjfeGUlWVhbVq1XlrgFXI4kff5rNnQ8+hiTMjL/2Ookdtt+2vE6jwuq6/96c9ZdTmDxlKuPHvQ/A9dffzlNPD+Xxx+5m0sSRbNiwkXP7XJrmmqZeHFIushRk+CXdCjQHLjazNaGsFtEwAvPNrMSnTCtqyqUiWTvv03RXIfZqtPSUT3nI3jB3i6PxZ81PSTrmdJ3/UkZG/1Qlja4HFgK/SPoqvGT6p1B2fYqO6ZxzpZa7GVOmKjHlEt6ccSawnZkNkNQWaG5mRY76FcZ8uTq8S699KJ5pZmslNQMWlEHdnXOuzBgZ2ejeLMm00B8mepCoV5hfSfQGjhKZ2Vozm0L0No4zJI0kGmXMOecySrYp6SlTJXNTdF8z2yuMsIiZLc17W3VxQm+W44EziEYeq0P0Dr1PtqC+zjmXEltLC31j6D9uEA3eTglpJEnPA9OJBnZ/AGhH9FbrUWaWySko59xWKg459GQC+v1E78RrKukWYDRQ0ohTuwBLid7S8V3IqXuvFedcxjKU9JSpkhlt8TlJXwGHED32f4KZfVfCNh0l7USUd/9A0m9AHUnNzMxviDrnMk4mt7yTlUwvl7bAGuDNxDIz+6W47czse6A/0F9SJ6Jc+jhJc8xs/y2rtnPOla2cDG55JyuZm6JvEaVLBFQHtgWmAbsmexAz+wr4StIVFBzjxTnnMkIZvYEurZJJueyeOB9GYbywuG0k/buE3XpPF+dcRsndSlroBZjZBEn7lrDa6kLKagF9gEbAgEKWO+dc2sSh10YyOfTLE2YrAXsB84rbxszyh96VVAe4BDgHGErxw/I651xabBU3RYkeCMqTTZRTf7mkjSQ1BC4nGjZgMLCXmS0tTSWdcy7VchXzlEt4oKiOmV2xOTuVdCdwEtHLKnY3s1Wlr6JzzqVeTrorUAaKfLBIUlZ4IKhrKfb7f0BL4DpgnqQVYVopaUUp6+qccymTq+SnTFVcC30sUb58kqQ3gOEk3Ow0syJfmGlmFf9dTs65rcrW0sulOrAYOJjf+6Mb4G9Ads7FRtx7uTQNPVy+4fdAnicO5+6cc/kyOZWSrOICemWgNhT6d4gHdOdcrMS92+KvZuYPADnntgo5MW+hx+D0nHMuOXFooRfXG+WQcquFc86lWVm94EJSG0kfSZoq6VtJl4TyhpJGSJoRfjYI5ZJ0v6SZkiaH8bLy9tU7rD9DUu+SzqHIgG5mS0ra2Dnn4sKU/FSCbOD/zGwXoAtwkaRdgKuBkWbWARgZ5gGOBDqEqS/wCOQ/bd8f2BfYh2go8gbFHdj7izvnHGXXQjezX81sQvi8kujNba2I3rE8OKw2mOgdy4TyIRb5EqgvqQVwODDCzJaEYVNGAEcUd2wP6M45R/Tof7KTpL6SxidMfQvbp6R2wJ7AGKCZmf0aFs0HmoXPrYDZCZvNCWVFlRdps4fPdc65ONqcfuhmNohorKoiSapNNJDhpWa2QgmDf5mZSSrz7t/eQnfOOcou5QIgqQpRMH8uYZiUBSGVQvi5MJTPBdokbN46lBVVXiQP6M45R5n2chHwBPCdmQ1MWPQGkNdTpTfwekL52aG3SxdgeUjNvAf0kNQg3AztEcqK5CkX55yjTB9/7wqcBUyRNCmUXQPcDrwoqQ/wM3BaWPY2cBQwE1hD9DIgzGyJpJuAcWG9ASX1PvSA7pxzlN1YLmY2mqIfzPzD8z1mZsBFRezrSeDJZI/tAd0554jHCy4yNqBnVaqc7irE3mEdC+1p5crQzS0OSncVXJJyYzDmYMYGdOecK09xGMvFA7pzzhGPMcE9oDvnHN5Cd8652Mgu+wc3y50HdOecw1MuzjkXG55ycc65mPBui845FxMVP5x7QHfOOcBTLs45Fxs5MWije0B3zjm8he6cc7Fh3kJ3zrl48Ba6c87FhHdbdM65mKj44dwDunPOAZAdg5DuAd055/Cbos45Fxt+U9Q552LCW+jOORcT3kJ3zrmYyDFvoTvnXCx4P3TnnIsJz6E751xMeA7dOediwlMuzjkXE55ycc65mPBeLs45FxOecnHOuZiIw03RSumugHPOZQLbjP9KIulJSQslfZNQ1lDSCEkzws8GoVyS7pc0U9JkSXslbNM7rD9DUu+SjusB3TnniFIuyU5JeBo4YpOyq4GRZtYBGBnmAY4EOoSpL/AIRF8AQH9gX2AfoH/el0BRPOWSpEcfvZMjjzyERYsW06nTYQCcdNLRXHfdZey0U3u6dTuOCRMmA9Cz5wlcdtl5+dvuvvvOdOlyFJMnT01L3SuSk/ucyDG9jgKJt55/m5eeeIU69evQ/+HraN6mGfNnL+CGC25i1aGIk6wAAA9CSURBVPJVdO2xP+de+VcsN5ec7BwevOERpoz7puSDbIWOuvPvbH9wR9YsXsETPfoB0HSXthx+y7lkVatCbk4O71/3NL9+/SP7nHc0ux6/PwCVsirRqH0r7t/zAtYtX80Fo+9h/ep1WE4uuTk5DD723+k8rTJlZXhT1Mw+kdRuk+LjgQPD58HAKOBfoXyIRRX4UlJ9SS3CuiPMbAmApBFEXxIvFHVcD+hJeuaZ4TzyyGCeeOKe/LJvv53G6af35aGHbiuw7tChrzF06GsA7Lrrjgwf/rgH8yRsu2M7jul1FOcfczHZGzdyx7O388XILznmzKOZ8NlEnn9oKGdc1JMzLurJoFsfZ8LoCXz2/ucAbLfzttzwyPWcfeC5aT6LzDRl+Cd8NXgExwz8vaFxUL9efHbfK/w4ajLbHbQHB/XrxfM9b2Hso28x9tG3AGh/yJ7s/bcjWLd8df52L/S8hbVLV5X7OaRazmbcFJXUl6g1nWeQmQ0qYbNmZvZr+DwfaBY+twJmJ6w3J5QVVV4kT7kkafTosSxduqxA2bRpM5kx48ditzv99OMZPvyNVFYtNtq2b8vUSd+zft16cnJymfTl13Q/shtde+zPu8PfB+Dd4e/T7fCuAKxdsy5/2+o1qpdpCytuZo+dxrplBYOwmVG1dg0AqtWpycqFS/+w3c7H78fU178olzqm2+akXMxskJl1TphKCuYFhNZ4mf/Cegs9xU455VhOOaVPuqtRIcya9hN/+9e51K1fl/Xr1tPl4H2ZNnk6DRs3YMnCJQAsWbiEho1/TyN2O6Irfa/uQ/3G9bn67GvTVfUKaeSAZzltyFUcfO0ZqJJ45qQbCyzPql6V7f78J0ZcPzi/zDBOf/ZqMGPicx/y9QsflXe1U6YcGgQLJLUws19DSmVhKJ8LtElYr3Uom8vvKZq88lHFHSAlAV1SZaCGma0K812AqmHxRDNbmYrjZpq99+7ImjVrmTp1erqrUiH8MvMXXnh4KHc+fzvr1qxj5rc/kJuT84f1Ev/hjX73M0a/+xl/2nd3+lx5Dv/X66ryrHKFtudfDuHDm55j2jvj2OnofTnqjr8z9Mzb85e3P3RP5o6fXiDd8uzJN7FqwVJqNqpLz2f/xZIf5jF77LR0VL/MlUM/9DeA3sDt4efrCeUXSxpKdAN0eQj67wG3JtwI7QH0K+4AqUq5/Ae4MGH+BeBK4HrguqI2ktRX0nhJ43NyKn6O7tRTj+PFF18veUWX7+2h73LeURdyySmXs3L5Smb/OJclvy2lYdOGADRs2pCli5f9YbvJY6bQom0L6jWoW95VrrB2O7k7094ZB8D3b42hxR7bF1i+y7H7MfWNgumWVQuitMyaxSuY/t5XtOhYcJuKrIy7Lb4AfAHsKGmOpD5EgfwwSTOAQ8M8wNvAj8BM4DFC7Aw3Q28CxoVpQN4N0qKkKqAfAgxMmF9mZscSfcN0LWqjxLxU5cq1U1S18iGJk08+huHD30x3VSqU+o3qA9C0ZVMOOLIbI18byecjvuCIU3sAcMSpPfJvhLZq1zJ/uw67tadKtSosX7qi/CtdQa1auJS2XXYGYJuuu7L0p/n5y6rVqUGbLjsx4/0J+WVValSjaq3q+Z/bHbAbi6bNKd9Kp1COWdJTScysl5m1MLMqZtbazJ4ws8VmdoiZdTCzQ/OCs0UuMrPtzWx3MxufsJ8nzax9mJ4q6bipyqFXMrPshPl/hcqZpAoZqYcMeYDu3fejceMGzJw5hptvHsiSJcsYOHAATZo05NVXn2Ly5Kkce+xZAHTvvi9z5sxj1qxf0lzzimXAoP7UbVCX7Oxs7r32AVatWM3zDw6l/3+v46ieR7BgzkJuuOAmAA44qjs9Tj6MnOxs1q/bwIALbk5z7TPXcfdfRNv9dqZGg9pc+OX9jL7nZd791xMcesNZVKpciez1G3nn6ify19/h8M7M+mQKG9euzy+r2bguJw+6FABlVWbq658z6+PJ5X4uqRKHR/+VihsBkr4D9tk0Vy6pHjDGzHYqaR/Vq7et+Fc3w3VpvEO6qxB7R1Runu4qbBWu/vlZbek+9mt1UNIx54u5H23x8VIhVSmXx4BhktrmFUjahiiX/niKjumcc6VmZklPmSolKRczGyhpDTBaUq1QvAq43cweScUxnXNuS8Qh5ZKyfuhm9l/gv5LqhPmVAJL2NrNxqTquc86Vhr/gIglmtlLSLpJ6Ab2AZUDnVB/XOec2R45V/AF0UxbQw8A0eUF8I7AN0NnMfkrVMZ1zrrQyOTeerJTcFJX0BfAW0RfGyWbWCVjpwdw5l6nKePjctEhVL5cFQB2i0cSahLLMvQrOua1eWT4pmi4pCehmdgKwO/AVcIOkWUADSfuk4njOObelcs2SnjJVKnu5LA/jGYwHGgAdgXsktTWzNsVv7Zxz5SuTW97JStVoi1nArcC5wM+AgLbAU8A5qTimc85tiTj0cklVDv1OoCGwrZl1MrO9gO2AehQchdE55zKCp1yKdgywgyX0AzKzFZIuAL4HLk3RcZ1zrlQ85VI0s0I6dZpZjqSKf9Wcc7GTyS3vZKUq5TJV0tmbFkr6C1EL3TnnMkocui2mqoV+EfCKpHOJui5C9Lh/DeDEFB3TOedKLcf++LrDiiZVoy3OBfaVdDCwayh+28xGpuJ4zjm3peLw6H9KB+cysw+BD1N5DOecKwuZ/Eh/slI+2qJzzlUE3kJ3zrmYiEMvFw/ozjmH90N3zrnYiMOj/x7QnXMOz6E751xseA7dOediwlvozjkXE94P3TnnYsJb6M45FxPey8U552LCb4o651xMeMrFOediwp8Udc65mPAWunPOxUQccuiKw7dSppDU18wGpbsecebXOPX8GldcqXqn6Naqb7orsBXwa5x6fo0rKA/ozjkXEx7QnXMuJjygly3PO6aeX+PU82tcQflNUeeciwlvoTvnXEx4QHfOuZjwgJ4kSc0lDZX0g6SvJL0taYew7FJJ6yTV22SbIySNlfS9pEmShklqm54zyGySTNLdCfNXSLphk3UmSRq6SVmWpFslzQjLJ0m6tpyqXeFIai3p9XC9fpB0n6SqCctfk/RlIdtdHn6Pp0j6WtJASVXKt/auJB7QkyBJwKvAKDPb3sw6Af2AZmGVXsA44KSEbXYDHgB6m9lOZtYReA5oV551r0DWAydJalzYQkk7A5WB7pJqJSy6GWgJ7B6ucXfAA00hwu/xK8BrZtYB2AGoDdwSltcHOgH1JG2XsN35QA+gi5ntDuwNLARqlO8ZuJL4TdEkSDoYuMHMDihk2fbAG8CFwLVm1iOUPwN8aGZPlWtlKyhJq4gCS20zu1bSFeHzDWH5AGAVsDMwwsyel1QTmA20M7OVaap6hSHpEKB/4u+xpLrALKAN0BPoDCwANprZrWGd2cABZjar/GvtNoe30JOzG/BVEct6AkOBT4EdJeW12ncFJpRD3eLkIeDMTVNXwelE1/kFor+IANoDv3gwT9qubPJ7bGYrgF+IrmUvouubf41DwK/twbxi8IC+5XoBQ80sF3gZOHXTFSQ1Crnd6aHl6QoRgssQ4J+J5ZI6A7+Z2S/ASGBPSQ033V7SOeE6z5bUplwqHR8NgA7AaDObDmwMacMCJB0ervFPkvYv91q6YnlAT863RLnFAiTtTvSPYISkn4ha670SttkLwMwWh/zuIKKcpSvavUAfIDFP3gvYKVzjH4C6wMnATKCtpDoAZvZUuM7LifLtrqCpbPJ7HFrgbYGOREF9VrjO7YBe4Ut2laRtAczsvXCNvwGq4jKKB/TkfAhUk5Q/aJGkPwH3E+XW24WpJdBS0jbAHcC14WZenprlWusKyMyWAC8SBXUkVQJOI7rp2c7M2gHHEwWbNcATwIOSqof1K+OBpigjgZqSzob8a3U38DRRSuuIhGvciaiBAnAb8Ei4aZp3c7V6+VbdJcMDehIsunN8InBo6Or1LdEv+YFEvV8SvQr0NLMpwCXAEEnTJH1GdEPv+fKreYV1N5DX26U7MNfM5iUs/wTYRVIL4FrgV+AbSROJ7mUMBhLXdxT4PT5V0gxgOrCO6C/HbYAvE9adBSyXtC/wCNGXwRhJk4HPgIlhchnEe7k451xMeAvdOediwgO6c87FhAd055yLCQ/ozjkXEx7QnXMuJjyguyJJyglPBX4jaXgYO6W0+3pa0inh8+OSdilm3QNL8xRieHrxD4N7FVVexD7+KunBsjiuc+XNA7orzloz62hmuwEbgPMTF0rKKs1OzexvZja1mFUOBPyxcuc2kwd0l6xPgfah9fyppDeAqZIqS7pT0jhJkyWdB9HThJIeDA9VfQA0zduRpFFhfJa8MeMnhDG2R0pqR/TFcVn466C7pCaSXg7HGCepa9i2kaT3JX0r6XFAyZ6MpH0kfSFpoqTPJe2YsLhNqOMMSf0TtvmLovHtJ0l6NDxp6VzGKFULy21dQkv8SODdULQXsJuZzQrDISw3s70lVQM+k/Q+sCewI7AL0bjxU4EnN9lvE+AxwtCskhqa2RJJ/wVWmdldYb3ngXvMbLSiF4S8R/TUbX+iwaQGSDqaMFxAkr4HuptZtqRDgVuJxocB2IdohM01wDhJbwGriR6P72pmGyU9DJxJNJiYcxnBA7orTg1Jk8LnT4nGTdkfGJswnGoP4E95+XGgHtGAZQcAL5hZDjBP0oeF7L8L8EnevsI4LoU5lOhR/7z5upJqh2OcFLZ9S9LSzTi3esBgSR0Ao+BLMUaY2WIASa8A3YBsovFNxoV61CB6yYNzGcMDuivO2jCyXr4QzFYnFgH/MLP3NlnvqDKsRyWit+WsK6QupXUT8JGZnRjSPKMSlm06HoYRnedgM+u3JQd1LpU8h+621HvABQrvl5S0g6JXxH0CnB5y7C2AgwrZ9kvggLyhWfX7GOcrgToJ670P/CNvRlLel8wnwBmh7Eii4V+TVQ+YGz7/dZNlh0lqKKkGcALRYFQjgVMkNc2raxhV07mM4QHdbanHifLjEyR9AzxK9Jffq8CMsGwI8MWmG5rZIqAv8Iqkr4FhYdGbwIl5N0WJXnjROdx0ncrvvW1uJPpC+JYo9fJLMfWcLGlOmAYSDW98WxihcdO/VMcSvaxkMvCymY0PvXKuA94PIw6OAFokeY2cKxc+2qJzzsWEt9Cdcy4mPKA751xMeEB3zrmY8IDunHMx4QHdOediwgO6c87FhAd055yLif8HBcT/U8H8lMoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RsZ4fb8Rl_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "8bbe3e84-6c2d-4562-df4d-5f435cb4c485"
      },
      "source": [
        "#train random forest models using the best parameters for Hindi\n",
        "rf_hi = RandomForestClassifier(n_estimators= 150, max_depth = 40, n_jobs = -1) ##PARAMS BASED ON OPTIMIZATION ABOVE\n",
        "rf_model_hi = rf_hi.fit(X_train_vect_hi, y_train_hi)\n",
        "y_pred_train = rf_model_hi.predict(X_train_vect_hi)\n",
        "y_pred_test = rf_model_hi.predict(X_test_vect_hi)\n",
        "\n",
        "#Hindi training data matrix\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#Hindi test data matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ad0d4a22e970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train random forest models using the best parameters for Hindi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_hi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##PARAMS BASED ON OPTIMIZATION ABOVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrf_model_hi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_hi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect_hi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_hi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model_hi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect_hi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model_hi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vect_hi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDCyj64jwtZ3"
      },
      "source": [
        "#Characterlevel ngrams into tf-idf vectorization\n",
        "\n",
        "#making ngrams tokens into string for tfidf vectorizer\n",
        "english_total['ngram_5_text']=english_total['ngram_5'].apply(lambda x: \"\".join(x))\n",
        "hindi_total['ngram_5_text']=hindi_total['ngram_5'].apply(lambda x: \"\".join(x))\n",
        "\n",
        "X_ngram = english_total[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post',\n",
        " 'ngram_5_text'\n",
        "]]\n",
        "y_ngram = english_total['agression']\n",
        "X_train_ngram, X_test_ngram, y_train_ngram, y_test_ngram = train_test_split(X_ngram,y_ngram, test_size=0.2, random_state=42)\n",
        "\n",
        "#TFIDF Vectorizer\n",
        "tfidf_vect_ngram = TfidfVectorizer()\n",
        "tfidf_vect_fit_ngram = tfidf_vect_ngram.fit(X_train_ngram['ngram_5_text'])\n",
        "\n",
        "tfidf_train_ngram = tfidf_vect_fit_ngram.transform(X_train_ngram['ngram_5_text'])\n",
        "tfidf_test_ngram = tfidf_vect_fit_ngram.transform(X_test_ngram['ngram_5_text'])\n",
        "\n",
        "X_train_vect_en_ngram = pd.concat([X_train_ngram[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_train_ngram.toarray())], axis=1)\n",
        "X_test_vect_en_ngram = pd.concat([X_test_ngram[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_test_ngram.toarray())], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQsy290EZNL"
      },
      "source": [
        "\n",
        "X_hi_ngram = hindi_total[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post',\n",
        " 'ngram_5_text'\n",
        "]]\n",
        "y_hi_ngram = hindi_total['agression']\n",
        "X_train_hi_ngram, X_test_hi_ngram, y_train_hi_ngram, y_test_hi_ngram = train_test_split(X_hi_ngram,y_hi_ngram, test_size=0.2, random_state=42)\n",
        "\n",
        "#TFIDF Vectorizer\n",
        "tfidf_vect_hi_ngram = TfidfVectorizer()\n",
        "tfidf_vect_fit_hi_ngram = tfidf_vect_ngram.fit(X_train_hi_ngram['ngram_5_text'])\n",
        "\n",
        "tfidf_train_hi_ngram = tfidf_vect_fit_ngram.transform(X_train_hi_ngram['ngram_5_text'])\n",
        "tfidf_test_hi_ngram = tfidf_vect_fit_ngram.transform(X_test_hi_ngram['ngram_5_text'])\n",
        "\n",
        "X_train_vect_hi_ngram = pd.concat([X_train_hi_ngram[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_train_hi_ngram.toarray())], axis=1)\n",
        "X_test_vect_hi_ngram = pd.concat([X_test_hi_ngram[['emoji_sentiment',\n",
        " 'number_of_emojis',\n",
        " 'profanity_prob',\n",
        " 'neg_score',\n",
        " 'neutral_score',\n",
        " 'pos_score',\n",
        " 'compound_score',\n",
        " 'punc_per_word',\n",
        " 'exclamation_punc_per_word',\n",
        " 'hashtags',\n",
        " 'num_numbers',\n",
        " 'num_capital_words',\n",
        " 'num_words_in_post']].reset_index(drop=True), \n",
        "           pd.DataFrame(tfidf_test_hi_ngram.toarray())], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnBLb20owiho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "daa1b599-8ee4-44a3-a4ec-f63bdffc0149"
      },
      "source": [
        "#SVM with characterlevel vectorizing + feature extraction for English Data \n",
        "from sklearn import svm\n",
        "clf_ngram = svm.SVC(kernel='RBF')\n",
        "svm_model_en_ngram = clf_ngram.fit(X_train_vect_en_ngram, y_train_ngram)\n",
        "y_pred_train_ngram = svm_model_en.predict(X_train_vect_en_ngram)\n",
        "y_pred_test_ngram = svm_model_en.predict(X_test_vect_en_ngram)\n",
        "\n",
        "#English training data matrix\n",
        "cm = confusion_matrix(y_train_ngram, y_pred_train_ngram)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(y_test_ngram, y_pred_test_ngram)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9d3333dbf191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RBF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msvm_model_en_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect_en_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred_train_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect_en_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vect_en_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_vect_en_ngram' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuYElhT279_l"
      },
      "source": [
        "#SVM with wordlevel vectorizing + feature extraction for English Data \n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf = OneVsRestClassifier(BaggingClassifier(svm.SVC(kernel='rbf', probability=True, class_weight='auto'), max_samples=1.0 / n_estimators, n_estimators=n_estimators))\n",
        "clf.fit(X, y)\n",
        "\n",
        "svm_model_en = clf.fit(X_train_vect_en, y_train)\n",
        "y_pred_train = svm_model_en.predict(X_train_vect_en)\n",
        "y_pred_test = svm_model_en.predict(X_test_vect_en)\n",
        "\n",
        "#English training data matrix\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9NL6Zjwyvc7"
      },
      "source": [
        "#SVM with wordlevel vectorizing + feature extraction for Hindi Data \n",
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='RBF')\n",
        "svm_model_en = clf.fit(X_train_vec, y_train)\n",
        "y_pred_train = svm_model_en.predict(X_train_vect)\n",
        "y_pred_test = svm_model_en.predict(X_test_vect)\n",
        "\n",
        "#English training data matrix\n",
        "cm = confusion_matrix(y_train, y_pred_train)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxh9tyiuyn3w"
      },
      "source": [
        "#SVM with characterlevel vectorizing + feature extraction for Hindi Data \n",
        "clf_hi_ngram = svm.SVC(kernel='RBF')\n",
        "svm_model_hi_ngram = clf.fit(X_train_vec_hi_ngram, y_train_hi_ngram)\n",
        "y_pred_train_hi_ngram = svm_model_hi_ngram.predict(X_train_hi_vect_ngram)\n",
        "y_pred_test_hi_ngram = svm_model_hi_ngram.predict(X_test_vect_hi_ngram)\n",
        "\n",
        "#English training data matrix\n",
        "cm = confusion_matrix(y_train_hi_ngram, y_pred_train_hi_ngram)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(y_test_hi_ngram, y_pred_test_hi_ngram)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAyXmKvIy6UN"
      },
      "source": [
        "#Baseline - SVM RBF with characterlevel vectorizer and NO feature extraction\n",
        "#English:\n",
        "clf_hi_ngram = svm.SVC(kernel='RBF')\n",
        "svm_model_hi_ngram_only = clf.fit(tfidf_train_ngram, y_train_hi_ngram)\n",
        "y_pred_train_hi_ngram_only = svm_model_hi_ngram_only.predict(tfidf_train_ngram)\n",
        "y_pred_test_hi_ngram_only = svm_model_hi_ngram_only.predict(tfidf_test_ngram)\n",
        "\n",
        "#English training data matrix\n",
        "cm = confusion_matrix(tfidf_train_ngram, y_pred_train_hi_ngram_only)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(tfidf_test_ngram, y_pred_test_hi_only)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Hindi: \n",
        "clf_hi_ngram = svm.SVC(kernel='RBF')\n",
        "svm_model_hi_ngram = clf.fit(X_train_vec_hi_ngram, y_train_hi_ngram)\n",
        "y_pred_train_hi_ngram = svm_model_hi_ngram.predict(X_train_hi_vect_ngram)\n",
        "y_pred_test_hi_ngram = svm_model_hi_ngram.predict(X_test_vect_hi_ngram)\n",
        "\n",
        "#English training data matrix\n",
        "cm = confusion_matrix(tfidf_train_hi_ngram, y_pred_train_hi_ngram)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "#English test data matrix\n",
        "cm = confusion_matrix(tfidf_test_hi_ngram, y_pred_test_hi_ngram)\n",
        "class_label = [\"CAG\", \"NAG\", \"OAG\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}